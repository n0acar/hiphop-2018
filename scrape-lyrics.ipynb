{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use \"requests\" to send request to our website. This process behaves as if we open the website on a browser but it saves the response of the website to an instance instead opening it graphically. We will be using the content of this response. \"BeautifulSoup\" helps us parse this content in a more useful way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoup(website):\n",
    "    sourceRequest = requests.get(website)\n",
    "    soup = BeautifulSoup(sourceRequest.content , 'html.parser')\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should check the website name and patterns in similar ones. In our example, lyrics page of an artist is formed in format of 'http://www.metrolyrics.com/artist-name-lyrics.html'. This type of patterns makes things easier for developers. In this case, you can change artist's name and see it works well for any artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayo teo\n"
     ]
    }
   ],
   "source": [
    "%store -r artist\n",
    "#artist='ayo teo'\n",
    "artist=artist.lower()\n",
    "print(artist)\n",
    "artistName=artist.replace(' ', '-').replace('.', '')\n",
    "artistPage = 'http://www.metrolyrics.com/' +artistName+ '-lyrics.html'\n",
    "artistSoups=[]\n",
    "artistSoup = getSoup(artistPage)\n",
    "artistSoups.append(artistSoup)\n",
    "isMultiplePaged=artistSoup.find('span', attrs={'class': 'pages'})\n",
    "pageIndex=2\n",
    "if isMultiplePaged is not None:\n",
    "    while True:\n",
    "        artistMultiplePage='http://www.metrolyrics.com/' +artistName+ '-alpage-' +str(pageIndex)+ '.html'\n",
    "        artistMultipleSoup=getSoup(artistMultiplePage)\n",
    "        if artistMultipleSoup==artistSoups[0]:\n",
    "            break\n",
    "        artistSoups.append(artistMultipleSoup)\n",
    "        pageIndex+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend you to print soup. If you are lucky, you'll see a well parsed source code of your website. In some cases, you might not see what you're looking in source code. Don't worry if that happens to you, I'll come to its solution later in the post. \n",
    "\n",
    "You need to inspect where your data is in the source code. I use Google Chrome for its \"Inspect\" feature to spot desired data in the source code. After this step, we are ready to use find and find_all functions in order to create lists of desired data.\n",
    "\n",
    "I wanted to shrink our source code to tbody in \"content\" div just to not let the wrong data in. I'll use the song lyrics links so our code should look for 'a' elements in \"content\" section. Then, I'll be doing some string manipulation which I assume you are familiar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "songLinkList={}\n",
    "for artistSoup in artistSoups:\n",
    "    contentTable=artistSoup.find('div', attrs={'class': 'content'})\n",
    "    tableBody=contentTable.find('tbody')\n",
    "    aList=tableBody.find_all('a')\n",
    "    for a in aList:\n",
    "        songLink=a['href']\n",
    "        rawNameText=a['title']\n",
    "        name=rawNameText.replace(artist.title(), '').replace('lyrics', '')[1:-1]\n",
    "        songLinkList[name]=songLink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleLyricsDict={}\n",
    "for title, lyrics in songLinkList.items():\n",
    "    lyricsSoup=getSoup(lyrics)\n",
    "    lyrics=lyricsSoup.find_all('p', attrs={'class': 'verse'})\n",
    "    lyricsList=''\n",
    "    for verse in lyrics:\n",
    "        desiredLyrics=verse.get_text().replace('\\n', '[|]')+'[|]'\n",
    "        lyricsList+=desiredLyrics\n",
    "        lyricsList=lyricsList.replace('[|][|]', '[|]')\n",
    "    titleLyricsDict[title]=lyricsList[:-3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayo-teo.csv file created\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(artistName + '.csv', 'w') as f:\n",
    "    for title, lyrics in titleLyricsDict.items():\n",
    "        f.write(\"%s,%s\\n\"%(title, lyrics))\n",
    "print(artistName + '.csv file created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
